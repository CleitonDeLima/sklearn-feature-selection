{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature Selection\n",
    "\n",
    "\n",
    "A seleção de recursos é um processo que seleciona automaticamente os recursos em seus dados que mais contribuem para a predição ou da saída em que você está interessado.\n",
    "\n",
    "Ter muitos recursos irrelevantes nos dados pode diminuir a precisão dos modelos.  \n",
    "Três benefícios de executar a seleção de recursos antes da modelagem dos dados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Reduzir Overfitting:  \n",
    "Dados menos redundantes significa menos oportunidades de tomar decisões.\n",
    "  \n",
    "- ##### Melhora a Accuracy:  \n",
    "Dados sem redundancia melhora os resultados de precisão.  \n",
    "\n",
    "- ##### Reduz o tempo de treinamento:  \n",
    "Com a remoção de alguns dados o treinamento se torna mais rapido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination - *RFE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dataset = datasets.load_iris()\n",
    "features = dataset.feature_names\n",
    "verb = 0\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 3, verbose=verb)\n",
    "rfe = rfe.fit(dataset.data, dataset.target)\n",
    "\n",
    "print('Melhores selecionados recebem ranking 1: ')\n",
    "for i, r in enumerate(rfe.ranking_):\n",
    "    print([r, features[i]])\n",
    "    \n",
    "print()\n",
    "\n",
    "print('Features usadas:')\n",
    "for i, s in enumerate(rfe.support_):\n",
    "    if s:\n",
    "        print(features[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination Cross-Validated - *RFECV*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dataset = datasets.load_iris()\n",
    "# dataset = datasets.load_breast_cancer()\n",
    "verb = 0\n",
    "\n",
    "features = dataset.feature_names\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "rfe = RFECV(model, cv=4, verbose=verb, step=1)\n",
    "rfe = rfe.fit(dataset.data, dataset.target)\n",
    "\n",
    "print('Melhores selecionados recebem ranking 1: ')\n",
    "for i, r in enumerate(rfe.ranking_): print([r, features[i]])\n",
    "    \n",
    "print()\n",
    "\n",
    "print('Features usadas:')\n",
    "for i, s in enumerate(rfe.support_):\n",
    "    if s: print(features[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VarianceThreshold\n",
    "  \n",
    "Podemos remover recursos onde a grande maioria das observações é de um tipo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Para features binárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Feature 0: 80% value 0\n",
    "# Feature 1: 80% value 1\n",
    "# Feature 2: 60% value 0, 40% value 1\n",
    "X = [[0, 1, 0],\n",
    "     [0, 1, 1],\n",
    "     [0, 1, 0],\n",
    "     [0, 1, 1],\n",
    "     [1, 0, 0]]\n",
    "\n",
    "# VAR = p(1 - p)\n",
    "\n",
    "p1 = .70  # 70%\n",
    "var = (p1 * (1 - p1))\n",
    "thresholder = VarianceThreshold(threshold=var)\n",
    "r = thresholder.fit_transform(X)\n",
    "print('Variância em t1: ')\n",
    "print(r)\n",
    "\n",
    "print()\n",
    "\n",
    "p2 = .80  # 80%\n",
    "var = (p2 * (1 - p2))\n",
    "thresholder = VarianceThreshold(threshold=var)\n",
    "r = thresholder.fit_transform(X)\n",
    "print('Variância em t2: ')\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Para features de qualquer valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "t = .18  # 50%\n",
    "thresholder = VarianceThreshold(threshold=t)\n",
    "X_high_variance = thresholder.fit_transform(X)\n",
    "\n",
    "X_high_variance[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif, f_regression\n",
    "\n",
    "# mutual_info_regression(X, y) -> Estimate mutual information for a continuous target variable.\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "selectors = []\n",
    "\n",
    "# list of statistical functions\n",
    "functions = [\n",
    "    chi2, \n",
    "    f_classif, \n",
    "    mutual_info_classif,\n",
    "    f_regression\n",
    "]\n",
    "\n",
    "for f in functions:\n",
    "    sel = SelectKBest(f, k=2)\n",
    "    sel.fit(X, y)\n",
    "    selectors.append(sel)\n",
    "    \n",
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sel in selectors:\n",
    "    print(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sel in selectors:\n",
    "    newX = sel.transform(X)\n",
    "    df = pd.DataFrame(newX).head()\n",
    "    print('Usando ', sel.score_func.__name__)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sel in selectors:\n",
    "    print('Score of: ', sel.score_func.__name__)\n",
    "    print(sel.scores_, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2, f_classif, mutual_info_classif, f_regression\n",
    "\n",
    "selectors = []\n",
    "functions = [\n",
    "    chi2, \n",
    "    f_classif, \n",
    "    mutual_info_classif,\n",
    "    f_regression\n",
    "]\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "for f in functions:\n",
    "    sel = SelectPercentile(f, percentile=80)\n",
    "    sel.fit(X, y)\n",
    "    selectors.append(sel)\n",
    "    \n",
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sel in selectors:\n",
    "    newX = sel.transform(X)\n",
    "    df = pd.DataFrame(newX).head()\n",
    "    print('Usando ', sel.score_func.__name__)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sel in selectors:\n",
    "    print('Score of: ', sel.score_func.__name__)\n",
    "    print(sel.transform(X).shape)\n",
    "    print(sel.scores_, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "sel = SelectFromModel(model, threshold=.5).fit(X, y)\n",
    "n_features = sel.transform(X).shape[1]\n",
    "\n",
    "while n_features > 2:\n",
    "    sel.threshold += 0.1\n",
    "    X_transform = sel.transform(X)\n",
    "    n_features = X_transform.shape[1]\n",
    "    \n",
    "X_transform.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GenericUnivariateSelect\n",
    "\n",
    "Usa Select* vistos anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, chi2\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# mode = {‘percentile’, ‘k_best’, ‘fpr’, ‘fdr’, ‘fwe’}\n",
    "X_transform = GenericUnivariateSelect(chi2, mode='k_best', param=2).fit_transform(X, y)\n",
    "X_transform.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectFpr, SelectFdr e SelectFwe\n",
    "\n",
    "Ver mais: [http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection](sklearn - Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
